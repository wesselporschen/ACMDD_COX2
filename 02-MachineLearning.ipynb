{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## This lab is in part adapted from TeachOpenCADD\n",
    "(https://noteable-beta.edina.ac.uk/user/wmk69tm57bfauozjthxzn1/tree/teachopencadd.git/teachopencadd/talktorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will load some libraries again first\n",
    "\n",
    "from pathlib import Path\n",
    "from warnings import filterwarnings\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics, clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score, recall_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
    "\n",
    "#from teachopencadd.utils import seed_everything\n",
    "\n",
    "# Silence some expected warnings\n",
    "filterwarnings(\"ignore\")\n",
    "# Fix seed for reproducible results\n",
    "SEED = 22\n",
    "#seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will look into cheminformatics. We ended the last session looking at the interaction of the ligand in the binding site. To refresh our minds, \n",
    "\n",
    "1. lets have another look at the protein-ligand interactions with PLIP:\n",
    "\n",
    " https://plip-tool.biotec.tu-dresden.de/plip-web/plip/index\n",
    " \n",
    " What also is informative is to do a short literature study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Find the Structure – Activity – Relationship (SAR) for your ligand. Use medicinal chemistry journals, like (but not limited to) J. Med. Chem., Bioorg Med Chem (Lett), ChemMedChem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. First, let's create a new working directory in your jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "HOMEDIR = str(Path.home())\n",
    "os.chdir(HOMEDIR)\n",
    "# We need to check whether the directory is there\n",
    "try:\n",
    "    os.mkdir('Cheminformatics')\n",
    "except:\n",
    "    print(\"Directory already exists\")\n",
    "os.chdir('Cheminformatics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next part, we need to have the SMILES (https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) representation of the molecule. You can retrieve this by going to the pdb, and fetch the InChI key for the ligand in your structure (use the RCSB accession code).\n",
    "\n",
    "4. The image below shows the InChI key for zma241385 in blue:\n",
    "![image info](img/LAB01_FIG00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using the InChI key, you can retrieve the SMILES from PubChem ((http://pubchem.ncbi.nlm.nih.gov/). Use the search bar where you paste the InChI key in, then run the search, you should retrieve the compound. Click on the entry, and you can find them under 2.1.4 Canonical Smiles. Write down the SMILES that you retrieved from PUBCHEM\n",
    "\n",
    "\n",
    "6.\tFind similar compounds by going to the Similarity tab, how many compounds were retrieved? Under settings, you can adjust the tanimoto threshold, change it to 80%, how much are retrieved now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tGo to https://www.ebi.ac.uk/chembl/, again use the InChI key from the previous step, click the entry. Write down the CHEMBLID. Next, do a Structure Search (button under the compound drawing).\n",
    "\n",
    "8.\tFetch 95% similar compounds, how much compounds were retrieved? Do the same but with 90%. Do you have more or less compounds than in step 6? Do you know why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tUse the Zinc site to search for possible similar ligands at http://zinc15.docking.org/substances/home/ .Again use the copied smiles string do a 70 % similar search (Tanimoto 70, written as similarity -30). Write down the number of hits and copy 1 representative molecule from each search. Discuss the results, how high is the impact of the similarity threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining and cleaning data.\n",
    "\n",
    "Let's now start with some data. You should have a CHEMBLID in your list, here we use CHEMBL251 (Adenosine A2a) as an example.\n",
    "\n",
    "10. We're going to download a dataset downloaded from ChEMBL, and read it into pandas, you can download the files from ChEMBL directly and upload them to the notebook environment (https://www.ebi.ac.uk/chembl/). Be sure to upload the extracted file (not the .zip file) and to give it a clear name so you can write it down in the below code block. \n",
    "\n",
    "\n",
    "Ask a TA if anything is unclear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 17698 datapoints in this set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule ChEMBL ID</th>\n",
       "      <th>Molecule Name</th>\n",
       "      <th>Molecule Max Phase</th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>#RO5 Violations</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Compound Key</th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Standard Type</th>\n",
       "      <th>Standard Relation</th>\n",
       "      <th>...</th>\n",
       "      <th>Target Type</th>\n",
       "      <th>Document ChEMBL ID</th>\n",
       "      <th>Source ID</th>\n",
       "      <th>Source Description</th>\n",
       "      <th>Document Journal</th>\n",
       "      <th>Document Year</th>\n",
       "      <th>Cell ChEMBL ID</th>\n",
       "      <th>Properties</th>\n",
       "      <th>Action Type</th>\n",
       "      <th>Standard Text Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL1619</td>\n",
       "      <td>CLADRIBINE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>285.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>CLADRIBINE</td>\n",
       "      <td>Nc1nc(Cl)nc2c1ncn2[C@H]1C[C@H](O)[C@@H](CO)O1</td>\n",
       "      <td>Ki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>CHEMBL1909046</td>\n",
       "      <td>15</td>\n",
       "      <td>DrugMatrix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHEMBL3833281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL268439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>13</td>\n",
       "      <td>Nc1ccc(S(=O)(=O)Nc2nnc(S(N)(=O)=O)s2)cc1</td>\n",
       "      <td>Ki</td>\n",
       "      <td>'='</td>\n",
       "      <td>...</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>CHEMBL1146805</td>\n",
       "      <td>1</td>\n",
       "      <td>Scientific Literature</td>\n",
       "      <td>Bioorg Med Chem Lett</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL1311</td>\n",
       "      <td>ISOSORBIDE MONONITRATE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>191.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>15, ISMN</td>\n",
       "      <td>O=[N+]([O-])O[C@@H]1CO[C@H]2[C@@H]1OC[C@@H]2O</td>\n",
       "      <td>Ki</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>CHEMBL1156128</td>\n",
       "      <td>1</td>\n",
       "      <td>Scientific Literature</td>\n",
       "      <td>Bioorg Med Chem Lett</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL20</td>\n",
       "      <td>ACETAZOLAMIDE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>222.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>138</td>\n",
       "      <td>CC(=O)Nc1nnc(S(N)(=O)=O)s1</td>\n",
       "      <td>Ki</td>\n",
       "      <td>'='</td>\n",
       "      <td>...</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>CHEMBL1133556</td>\n",
       "      <td>1</td>\n",
       "      <td>Scientific Literature</td>\n",
       "      <td>J Med Chem</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL331282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>SAB</td>\n",
       "      <td>NCCCCNC(=O)c1ccc(S(N)(=O)=O)cc1</td>\n",
       "      <td>Inhibition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>SINGLE PROTEIN</td>\n",
       "      <td>CHEMBL1135542</td>\n",
       "      <td>1</td>\n",
       "      <td>Scientific Literature</td>\n",
       "      <td>J Med Chem</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Molecule ChEMBL ID           Molecule Name  Molecule Max Phase  \\\n",
       "0         CHEMBL1619              CLADRIBINE                 4.0   \n",
       "1       CHEMBL268439                     NaN                 NaN   \n",
       "2         CHEMBL1311  ISOSORBIDE MONONITRATE                 4.0   \n",
       "3           CHEMBL20           ACETAZOLAMIDE                 4.0   \n",
       "4       CHEMBL331282                     NaN                 NaN   \n",
       "\n",
       "   Molecular Weight  #RO5 Violations  AlogP Compound Key  \\\n",
       "0            285.69              0.0  -0.30   CLADRIBINE   \n",
       "1            335.39              0.0  -0.43           13   \n",
       "2            191.14              0.0  -1.28     15, ISMN   \n",
       "3            222.25              0.0  -0.86          138   \n",
       "4            271.34              0.0  -0.20          SAB   \n",
       "\n",
       "                                          Smiles Standard Type  \\\n",
       "0  Nc1nc(Cl)nc2c1ncn2[C@H]1C[C@H](O)[C@@H](CO)O1            Ki   \n",
       "1       Nc1ccc(S(=O)(=O)Nc2nnc(S(N)(=O)=O)s2)cc1            Ki   \n",
       "2  O=[N+]([O-])O[C@@H]1CO[C@H]2[C@@H]1OC[C@@H]2O            Ki   \n",
       "3                     CC(=O)Nc1nnc(S(N)(=O)=O)s1            Ki   \n",
       "4                NCCCCNC(=O)c1ccc(S(N)(=O)=O)cc1    Inhibition   \n",
       "\n",
       "  Standard Relation  ...     Target Type Document ChEMBL ID  Source ID  \\\n",
       "0               NaN  ...  SINGLE PROTEIN      CHEMBL1909046         15   \n",
       "1               '='  ...  SINGLE PROTEIN      CHEMBL1146805          1   \n",
       "2               NaN  ...  SINGLE PROTEIN      CHEMBL1156128          1   \n",
       "3               '='  ...  SINGLE PROTEIN      CHEMBL1133556          1   \n",
       "4               NaN  ...  SINGLE PROTEIN      CHEMBL1135542          1   \n",
       "\n",
       "      Source Description      Document Journal Document Year  Cell ChEMBL ID  \\\n",
       "0             DrugMatrix                   NaN           NaN   CHEMBL3833281   \n",
       "1  Scientific Literature  Bioorg Med Chem Lett        2004.0             NaN   \n",
       "2  Scientific Literature  Bioorg Med Chem Lett        2009.0             NaN   \n",
       "3  Scientific Literature            J Med Chem        2000.0             NaN   \n",
       "4  Scientific Literature            J Med Chem        2002.0             NaN   \n",
       "\n",
       "   Properties  Action Type  Standard Text Value  \n",
       "0         NaN          NaN                  NaN  \n",
       "1         NaN          NaN                  NaN  \n",
       "2         NaN          NaN                  NaN  \n",
       "3         NaN          NaN                  NaN  \n",
       "4         NaN          NaN                  NaN  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHEMBLID = 'CHEMBL205' # Enter the CHEMBL ID of your target here\n",
    "FILENAME = 'CHEMBL205.tsv' # The filename of the uploaded file\n",
    "\n",
    "data = pd.read_csv(FILENAME, sep='\\t')\n",
    "\n",
    "print(\"There are a total of {} datapoints in this set\".format(len(data)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will note that we have a lot of data, and we certainly don't need it all, thus we're going to remove quite some columns.\n",
    "\n",
    "11. Actually, for now we only need the compound ID, pCHEMBL_value, Assay Type, binding affinity and the smiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule ChEMBL ID</th>\n",
       "      <th>pChEMBL_value</th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Assay_Type</th>\n",
       "      <th>Standard Relation</th>\n",
       "      <th>Standard Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL1619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nc1nc(Cl)nc2c1ncn2[C@H]1C[C@H](O)[C@@H](CO)O1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL268439</td>\n",
       "      <td>8.70</td>\n",
       "      <td>Nc1ccc(S(=O)(=O)Nc2nnc(S(N)(=O)=O)s2)cc1</td>\n",
       "      <td>B</td>\n",
       "      <td>'='</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL1311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O=[N+]([O-])O[C@@H]1CO[C@H]2[C@@H]1OC[C@@H]2O</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEMBL20</td>\n",
       "      <td>7.92</td>\n",
       "      <td>CC(=O)Nc1nnc(S(N)(=O)=O)s1</td>\n",
       "      <td>B</td>\n",
       "      <td>'='</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHEMBL331282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCCCCNC(=O)c1ccc(S(N)(=O)=O)cc1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Molecule ChEMBL ID  pChEMBL_value  \\\n",
       "0         CHEMBL1619            NaN   \n",
       "1       CHEMBL268439           8.70   \n",
       "2         CHEMBL1311            NaN   \n",
       "3           CHEMBL20           7.92   \n",
       "4       CHEMBL331282            NaN   \n",
       "\n",
       "                                          Smiles Assay_Type Standard Relation  \\\n",
       "0  Nc1nc(Cl)nc2c1ncn2[C@H]1C[C@H](O)[C@@H](CO)O1          B               NaN   \n",
       "1       Nc1ccc(S(=O)(=O)Nc2nnc(S(N)(=O)=O)s2)cc1          B               '='   \n",
       "2  O=[N+]([O-])O[C@@H]1CO[C@H]2[C@@H]1OC[C@@H]2O          B               NaN   \n",
       "3                     CC(=O)Nc1nnc(S(N)(=O)=O)s1          B               '='   \n",
       "4                NCCCCNC(=O)c1ccc(S(N)(=O)=O)cc1          B               NaN   \n",
       "\n",
       "   Standard Value  \n",
       "0             NaN  \n",
       "1             2.0  \n",
       "2             NaN  \n",
       "3            12.0  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data = data[['Molecule ChEMBL ID','pChEMBL Value','Smiles','Assay Type', 'Standard Relation','Standard Value']]\n",
    "pd_data.rename(columns={'pChEMBL Value': 'pChEMBL_value', 'Assay Type':'Assay_Type'}, inplace=True)\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add an activity classifier, there is a lot of censored data in the set and these typically are compounds that only bind weakly! We still want to know about those non-binders though.\n",
    "\n",
    "Let's set our activity threshold at PChEMBL > 6.5 for the actives, if you want to know more details have a look at this paper: https://jcheminf.biomedcentral.com/articles/10.1186/s13321-017-0232-0\n",
    "\n",
    "12. Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of active compounds: 9304\n",
      "Number of inactive compounds: 8394\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Add column for activity\n",
    "pd_data[\"active\"] = np.zeros(len(pd_data))\n",
    "\n",
    "# Mark every molecule as active with an pCHEMBL of >= 6.5, 0 otherwise\n",
    "pd_data.loc[pd_data[pd_data.pChEMBL_value >= 6.5].index, \"active\"] = 1.0\n",
    "\n",
    "# NBVAL_CHECK_OUTPUT\n",
    "print(\"Number of active compounds:\", int(pd_data.active.sum()))\n",
    "print(\"Number of inactive compounds:\", len(pd_data) - int(pd_data.active.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will drop functional assay readout, this is data that we don't want to consider in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 17030 activity points left\n"
     ]
    }
   ],
   "source": [
    "pd_data.drop(pd_data[pd_data.Assay_Type != 'B'].index, inplace=True)\n",
    "\n",
    "print(\"We have a total of {} activity points left\".format(len(pd_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to this notebook\n",
    "HERE = Path(_dh[-1])\n",
    "DATA = HERE / \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Molecule encoding\n",
    "\n",
    "Now we define a function `smiles_to_fp` to generate fingerprints from SMILES.\n",
    "For now, we incorporated the choice between the following fingerprints:\n",
    "\n",
    "* maccs\n",
    "* morgan2 and morgan3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_fp(smiles, method=\"maccs\", n_bits=2048):\n",
    "    \"\"\"\n",
    "    Encode a molecule from a SMILES string into a fingerprint.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles : str\n",
    "        The SMILES string defining the molecule.\n",
    "\n",
    "    method : str\n",
    "        The type of fingerprint to use. Default is MACCS keys.\n",
    "\n",
    "    n_bits : int\n",
    "        The length of the fingerprint.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        The fingerprint array.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert smiles to RDKit mol object\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        \n",
    "    except:\n",
    "        return('NaN')\n",
    "\n",
    "    if method == \"maccs\":\n",
    "        return np.array(MACCSkeys.GenMACCSKeys(mol))\n",
    "    if method == \"morgan2\":\n",
    "        return np.array(GetMorganFingerprintAsBitVect(mol, 2, nBits=n_bits))\n",
    "    if method == \"morgan3\":\n",
    "        return np.array(GetMorganFingerprintAsBitVect(mol, 3, nBits=n_bits))\n",
    "    else:\n",
    "        # NBVAL_CHECK_OUTPUT\n",
    "        print(f\"Warning: Wrong method specified: {method}. Default will be used instead.\")\n",
    "        return np.array(MACCSkeys.GenMACCSKeys(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_df = pd_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.2 in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas==2.2.2) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas==2.2.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas==2.2.2) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Molecule ChEMBL ID</th>\n",
       "      <th>pChEMBL_value</th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Assay_Type</th>\n",
       "      <th>Standard Relation</th>\n",
       "      <th>Standard Value</th>\n",
       "      <th>active</th>\n",
       "      <th>fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHEMBL1619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nc1nc(Cl)nc2c1ncn2[C@H]1C[C@H](O)[C@@H](CO)O1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHEMBL268439</td>\n",
       "      <td>8.7</td>\n",
       "      <td>Nc1ccc(S(=O)(=O)Nc2nnc(S(N)(=O)=O)s2)cc1</td>\n",
       "      <td>B</td>\n",
       "      <td>'='</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHEMBL1311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O=[N+]([O-])O[C@@H]1CO[C@H]2[C@@H]1OC[C@@H]2O</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Molecule ChEMBL ID  pChEMBL_value  \\\n",
       "0         CHEMBL1619            NaN   \n",
       "1       CHEMBL268439            8.7   \n",
       "2         CHEMBL1311            NaN   \n",
       "\n",
       "                                          Smiles Assay_Type Standard Relation  \\\n",
       "0  Nc1nc(Cl)nc2c1ncn2[C@H]1C[C@H](O)[C@@H](CO)O1          B               NaN   \n",
       "1       Nc1ccc(S(=O)(=O)Nc2nnc(S(N)(=O)=O)s2)cc1          B               '='   \n",
       "2  O=[N+]([O-])O[C@@H]1CO[C@H]2[C@@H]1OC[C@@H]2O          B               NaN   \n",
       "\n",
       "   Standard Value  active                                                 fp  \n",
       "0             NaN     0.0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1             2.0     1.0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2             NaN     0.0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column for fingerprint\n",
    "compound_df[\"fp\"] = compound_df[\"Smiles\"].apply(smiles_to_fp)\n",
    "# compound_df.drop(compound_df[compound_df.fp == 'NaN'].index, inplace=True)\n",
    "compound_df.dropna(subset=['fp'], inplace=True)\n",
    "compound_df.head(3)\n",
    "# NBVAL_CHECK_OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning (ML)\n",
    "\n",
    "In the following, we will try several ML approaches to classify our molecules. We will use:\n",
    "\n",
    "* Random Forest (RF)\n",
    "* Support Vector Machine (SVM) \n",
    "* Artificial Neural Network (ANN) \n",
    "\n",
    "Additionally, we will comment on the results.\n",
    "\n",
    "The goal is to test the ability of the model to predict data which it has never seen before in order to flag problems known as over fitting and to assess the generalization ability of the model.\n",
    "\n",
    "We start by defining a function `model_training_and_validation` which fits a model on a random train-test split of the data and returns measures such as accuracy, sensitivity, specificity and AUC evaluated on the test set. We also plot the ROC curves using `plot_roc_curves_for_models`.\n",
    "\n",
    "We then define a function named `crossvalidation` which executes a cross validation procedure and prints the statistics of the results over the folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "Helper function to plot customized ROC curves. Code inspired by [stackoverflow](https://stackoverflow.com/questions/42894871/how-to-plot-multiple-roc-curves-in-one-plot-with-legend-and-auc-scores-in-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves_for_models(models, test_x, test_y, save_png=True):\n",
    "    \"\"\"\n",
    "    Helper function to plot customized roc curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models: dict\n",
    "        Dictionary of pretrained machine learning models.\n",
    "    test_x: list\n",
    "        Molecular fingerprints for test set.\n",
    "    test_y: list\n",
    "        Associated activity labels for test set.\n",
    "    save_png: bool\n",
    "        Save image to disk (default = False)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig:\n",
    "        Figure.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Below for loop iterates through your models list\n",
    "    for model in models:\n",
    "        # Select the model\n",
    "        ml_model = model[\"model\"]\n",
    "        # Prediction probability on test set\n",
    "        test_prob = ml_model.predict_proba(test_x)[:, 1]\n",
    "        # Prediction class on test set\n",
    "        test_pred = ml_model.predict(test_x)\n",
    "        # Compute False postive rate and True positive rate\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_y, test_prob)\n",
    "        # Calculate Area under the curve to display on the plot\n",
    "        auc = roc_auc_score(test_y, test_prob)\n",
    "        # Plot the computed values\n",
    "        ax.plot(fpr, tpr, label=(f\"{model['label']} AUC area = {auc:.2f}\"))\n",
    "\n",
    "    # Custom settings for the plot\n",
    "    ax.plot([0, 1], [0, 1], \"r--\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(\"Receiver Operating Characteristic\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    # Save plot\n",
    "    if save_png:\n",
    "        fig.savefig(f\"results/roc_auc\", dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to calculate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(ml_model, test_x, test_y, verbose=True):\n",
    "    \"\"\"\n",
    "    Helper function to calculate model performance\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    test_x: list\n",
    "        Molecular fingerprints for test set.\n",
    "    test_y: list\n",
    "        Associated activity labels for test set.\n",
    "    verbose: bool\n",
    "        Print performance measure (default = True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple:\n",
    "        Accuracy, sensitivity, specificity, auc on test set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prediction probability on test set\n",
    "    test_prob = ml_model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "    # Prediction class on test set\n",
    "    test_pred = ml_model.predict(test_x)\n",
    "\n",
    "    # Performance of model on test set\n",
    "    accuracy = accuracy_score(test_y, test_pred)\n",
    "    sens = recall_score(test_y, test_pred)\n",
    "    spec = recall_score(test_y, test_pred, pos_label=0)\n",
    "    auc = roc_auc_score(test_y, test_prob)\n",
    "\n",
    "    if verbose:\n",
    "        # Print performance results\n",
    "        # NBVAL_CHECK_OUTPUT        print(f\"Accuracy: {accuracy:.2}\")\n",
    "        print(f\"Sensitivity: {sens:.2f}\")\n",
    "        print(f\"Specificity: {spec:.2f}\")\n",
    "        print(f\"AUC: {auc:.2f}\")\n",
    "\n",
    "    return accuracy, sens, spec, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Helper function to fit a machine learning model on a random train-test split of the data and return the performance measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training_and_validation(ml_model, name, splits, verbose=True):\n",
    "    \"\"\"\n",
    "    Fit a machine learning model on a random train-test split of the data\n",
    "    and return the performance measures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    name: str\n",
    "        Name of machine learning algorithm: RF, SVM, ANN\n",
    "    splits: list\n",
    "        List of desciptor and label data: train_x, test_x, train_y, test_y.\n",
    "    verbose: bool\n",
    "        Print performance info (default = True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple:\n",
    "        Accuracy, sensitivity, specificity, auc on test set.\n",
    "\n",
    "    \"\"\"\n",
    "    train_x, test_x, train_y, test_y = splits\n",
    "\n",
    "    # Fit the model\n",
    "    ml_model.fit(train_x, train_y)\n",
    "\n",
    "    # Calculate model performance results\n",
    "    accuracy, sens, spec, auc = model_performance(ml_model, test_x, test_y, verbose)\n",
    "\n",
    "    return accuracy, sens, spec, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**: Split the data (will be reused for the other models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 13624\n",
      "Test data size: 3406\n"
     ]
    }
   ],
   "source": [
    "fingerprint_to_model = compound_df.fp.tolist()\n",
    "label_to_model = compound_df.active.tolist()\n",
    "\n",
    "# Split data randomly in train and test set\n",
    "# note that we use test/train_x for the respective fingerprint splits\n",
    "# and test/train_y for the respective label splits\n",
    "(\n",
    "    static_train_x,\n",
    "    static_test_x,\n",
    "    static_train_y,\n",
    "    static_test_y,\n",
    ") = train_test_split(fingerprint_to_model, label_to_model, test_size=0.2, random_state=12)\n",
    "splits = [static_train_x, static_test_x, static_train_y, static_test_y]\n",
    "# NBVAL_CHECK_OUTPUT\n",
    "print(\"Training data size:\", len(static_train_x))\n",
    "print(\"Test data size:\", len(static_test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest classifier\n",
    "\n",
    "We start with a random forest classifier, where we first set the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model on a random train-test split and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model parameter for random forest\n",
    "param = {\n",
    "    \"n_estimators\": 100,  # number of trees to grows\n",
    "    \"criterion\": \"entropy\",  # cost function to be optimized for a split\n",
    "}\n",
    "model_RF = RandomForestClassifier(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (13624,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit model on single split\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m performance_measures \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_training_and_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_RF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m, in \u001b[0;36mmodel_training_and_validation\u001b[0;34m(ml_model, name, splits, verbose)\u001b[0m\n\u001b[1;32m     23\u001b[0m train_x, test_x, train_y, test_y \u001b[38;5;241m=\u001b[39m splits\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mml_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Calculate model performance results\u001b[39;00m\n\u001b[1;32m     29\u001b[0m accuracy, sens, spec, auc \u001b[38;5;241m=\u001b[39m model_performance(ml_model, test_x, test_y, verbose)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:1192\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1190\u001b[0m     )\n\u001b[0;32m-> 1192\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1210\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/validation.py:951\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    949\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 951\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    955\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/utils/_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (13624,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Fit model on single split\n",
    "performance_measures = model_training_and_validation(model_RF, \"RF\", splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the list that stores all models. First one is RF.\n",
    "models = [{\"label\": \"Model_RF\", \"model\": model_RF}]\n",
    "try:\n",
    "    os.mkdir('results')\n",
    "except:\n",
    "    print(\"Directory already exists, continuing\")\n",
    "# Plot roc curve\n",
    "plot_roc_curves_for_models(models, static_test_x, static_test_y)\n",
    "result_img = '{}/results/roc_auc.png'.format(os.getcwd())\n",
    "result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support vector classifier\n",
    "Here we train a SVM with a radial-basis function kernel (also: squared-exponential kernel). \n",
    "For more information, see [sklearn RBF kernel](http://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify model\n",
    "model_SVM = svm.SVC(kernel=\"rbf\", C=1, gamma=0.1, probability=True)\n",
    "\n",
    "# Fit model on single split\n",
    "performance_measures = model_training_and_validation(model_SVM, \"SVM\", splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "# Append SVM model\n",
    "models.append({\"label\": \"Model_SVM\", \"model\": model_SVM})\n",
    "# Plot roc curve\n",
    "plot_roc_curves_for_models(models, static_test_x, static_test_y)\n",
    "result_img = '{}/results/roc_auc.png'.format(os.getcwd())\n",
    "result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network classifier\n",
    "The last approach we try here is a neural network model. We train an MLPClassifier (Multi-layer Perceptron classifier) with 3 layers, each with 5 neurons. As before, we do the crossvalidation procedure and plot the results. For more information on MLP, see [sklearn MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify model\n",
    "model_ANN = MLPClassifier(hidden_layer_sizes=(5, 3), random_state=12)\n",
    "\n",
    "# Fit model on single split\n",
    "performance_measures = model_training_and_validation(model_ANN, \"ANN\", splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append ANN model\n",
    "models.append({\"label\": \"Model_ANN\", \"model\": model_ANN})\n",
    "# Plot roc curve\n",
    "plot_roc_curves_for_models(models, static_test_x, static_test_y, True)\n",
    "result_img = '{}/results/roc_auc.png'.format(os.getcwd())\n",
    "result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our models show very good values for all measured values (see AUCs) and thus seem to be predictive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation\n",
    "\n",
    "Next, we will perform cross-validation experiments with the three different models.\n",
    "Therefore, we define a helper function for machine learning model training and validation in a cross-validation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation(ml_model, df, n_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Machine learning model training and validation in a cross-validation loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    df: pd.DataFrame\n",
    "        Data set with SMILES and their associated activity labels.\n",
    "    n_folds: int, optional\n",
    "        Number of folds for cross-validation.\n",
    "    verbose: bool, optional\n",
    "        Performance measures are printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    # Shuffle the indices for the k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Results for each of the cross-validation folds\n",
    "    acc_per_fold = []\n",
    "    sens_per_fold = []\n",
    "    spec_per_fold = []\n",
    "    auc_per_fold = []\n",
    "\n",
    "    # Loop over the folds\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        # clone model -- we want a fresh copy per fold!\n",
    "        fold_model = clone(ml_model)\n",
    "        # Training\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        train_x = df.iloc[train_index].fp.tolist()\n",
    "        train_y = df.iloc[train_index].active.tolist()\n",
    "\n",
    "        # Fit the model\n",
    "        fold_model.fit(train_x, train_y)\n",
    "\n",
    "        # Testing\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        test_x = df.iloc[test_index].fp.tolist()\n",
    "        test_y = df.iloc[test_index].active.tolist()\n",
    "\n",
    "        # Performance for each fold\n",
    "        accuracy, sens, spec, auc = model_performance(fold_model, test_x, test_y, verbose)\n",
    "\n",
    "        # Save results\n",
    "        acc_per_fold.append(accuracy)\n",
    "        sens_per_fold.append(sens)\n",
    "        spec_per_fold.append(spec)\n",
    "        auc_per_fold.append(auc)\n",
    "\n",
    "    # Print statistics of results\n",
    "    print(\n",
    "        f\"Mean accuracy: {np.mean(acc_per_fold):.2f} \\t\"\n",
    "        f\"and std : {np.std(acc_per_fold):.2f} \\n\"\n",
    "        f\"Mean sensitivity: {np.mean(sens_per_fold):.2f} \\t\"\n",
    "        f\"and std : {np.std(sens_per_fold):.2f} \\n\"\n",
    "        f\"Mean specificity: {np.mean(spec_per_fold):.2f} \\t\"\n",
    "        f\"and std : {np.std(spec_per_fold):.2f} \\n\"\n",
    "        f\"Mean AUC: {np.mean(auc_per_fold):.2f} \\t\"\n",
    "        f\"and std : {np.std(auc_per_fold):.2f} \\n\"\n",
    "        f\"Time taken : {time.time() - t0:.2f}s\\n\"\n",
    "    )\n",
    "\n",
    "    return acc_per_fold, sens_per_fold, spec_per_fold, auc_per_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-validation**\n",
    "\n",
    "We now apply cross-validation and show the statistics for all three ML models. In real world conditions, cross-validation usually applies 5 or more folds, but for the sake of performance we will reduce it to 3. You can change the value of `N_FOLDS` in this cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: Next cell takes long to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(\"\\n======= \")\n",
    "    print(f\"{model['label']}\")\n",
    "    crossvalidation(model[\"model\"], compound_df, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the cross-validation performance for molecules encoded using Morgan fingerprint and not MACCS keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset data frame\n",
    "compound_df = compound_df.drop(['fp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Morgan fingerprint with radius 3\n",
    "compound_df[\"fp\"] = compound_df[\"Smiles\"].apply(smiles_to_fp, args=(\"morgan3\",))\n",
    "compound_df.head(3)\n",
    "# NBVAL_CHECK_OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_: Next cell takes long to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    if model[\"label\"] == \"Model_SVM\":\n",
    "        # SVM is super slow with long fingerprints\n",
    "        # and will have a performance similar to RF\n",
    "        # We can skip it in this test, but if you want\n",
    "        # to run it, feel free to replace `continue` with `pass`\n",
    "        continue\n",
    "    print(\"\\n=======\")\n",
    "    print(model[\"label\"])\n",
    "    reduced_df = compound_df[['active','fp']]\n",
    "    crossvalidation(model[\"model\"], reduced_df, n_folds=N_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have been running classification models (is the compound going to be active or not, indicated by the active column we added in the dataframe). The next step is to see if we can also train a classification model. We will remove the censored data (the ones with no pChEMBL value), and train another model. \n",
    "\n",
    "Make a new function that works with regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidation_reg(ml_model, df, n_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Machine learning model training and validation in a cross-validation loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ml_model: sklearn model object\n",
    "        The machine learning model to train.\n",
    "    df: pd.DataFrame\n",
    "        Data set with SMILES and their associated activity labels.\n",
    "    n_folds: int, optional\n",
    "        Number of folds for cross-validation.\n",
    "    verbose: bool, optional\n",
    "        Performance measures are printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    # Shuffle the indices for the k-fold cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Results for each of the cross-validation folds\n",
    "    MAE_per_fold = []\n",
    "    RMSE_per_fold = []\n",
    "\n",
    "    # Loop over the folds\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        # clone model -- we want a fresh copy per fold!\n",
    "        fold_model = clone(ml_model)\n",
    "        # Training\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        train_x = df.iloc[train_index].fp.tolist()\n",
    "        train_y = df.iloc[train_index].pChEMBL_value.tolist()\n",
    "\n",
    "        # Fit the model\n",
    "        fold_model.fit(train_x, train_y)\n",
    "\n",
    "        # Testing\n",
    "\n",
    "        # Convert the fingerprint and the label to a list\n",
    "        test_x = df.iloc[test_index].fp.tolist()\n",
    "        test_y = df.iloc[test_index].pChEMBL_value.tolist()\n",
    "        \n",
    "        test_results = fold_model.predict(test_x)\n",
    "        # Prediction probability on test set\n",
    "        from sklearn import metrics\n",
    "\n",
    "        MAE_per_fold.append(metrics.mean_absolute_error(test_y, test_results))\n",
    "        #print('Mean Squared Error (MSE):', metrics.mean_squared_error(test_y, test_results))\n",
    "        RMSE_per_fold.append(np.sqrt(metrics.mean_squared_error(test_y, test_results)))\n",
    "        #mape = np.mean(np.abs((gt - pred) / np.abs(gt)))\n",
    "        #print('Mean Absolute Percentage Error (MAPE):', round(mape * 100, 2))\n",
    "        #print('Accuracy:', round(100*(1 - mape), 2))\n",
    "    return(MAE_per_fold,RMSE_per_fold,fold_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, make new data and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_to_model = compound_df.fp.tolist()\n",
    "label_to_model = compound_df.pChEMBL_value.tolist()\n",
    "\n",
    "# Split data randomly in train and test set\n",
    "# note that we use test/train_x for the respective fingerprint splits\n",
    "# and test/train_y for the respective label splits\n",
    "(\n",
    "    static_train_x,\n",
    "    static_test_x,\n",
    "    static_train_y,\n",
    "    static_test_y,\n",
    ") = train_test_split(fingerprint_to_model, label_to_model, test_size=0.2, random_state=12)\n",
    "splits = [static_train_x, static_test_x, static_train_y, static_test_y]\n",
    "# NBVAL_CHECK_OUTPUT\n",
    "print(\"Training data size:\", len(static_train_x))\n",
    "print(\"Test data size:\", len(static_test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Kick out NaN in the pChEMBL values\n",
    "compound_df_noNaN = compound_df.dropna()\n",
    "\n",
    "# Append RF Regressor model\n",
    "#models.append({\"label\": \"Model_RF_reg\", \"model\": RandomForestRegressor})\n",
    "#Train model with RandomForestRegressor\n",
    "regressor = RandomForestRegressor()\n",
    "MAE, RMSE,trained_model = crossvalidation_reg(regressor , compound_df_noNaN, n_folds=N_FOLDS)\n",
    "\n",
    "print(\n",
    "f\"MAE: {np.mean(MAE):.2f} \\t\"\n",
    "f\"and std : {np.std(MAE):.2f} \\n\"\n",
    "f\"RMSE: {np.mean(RMSE):.2f} \\t\"\n",
    "f\"and std : {np.std(RMSE):.2f} \\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that we report different measures of accuracy. We no longer deal with categorical data so we now look at the errors between experimental data and predicted data using the MAE and RMSE. Typically, an MAE below 0.6 and/or RMSE below, approximately, is considered quite decent.\n",
    "\n",
    "Next, let's use the RF model to run predictions on a new compound. You can design your compounds in a sketcher (chemdraw (https://chemdrawdirect.perkinelmer.cloud/js/sample/index.html#) or an online tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first entry is the co-crystalized ligand \n",
    "# which is added for reference (so we can compare \n",
    "# to its actual pChEMBL value)\n",
    "# BELOW: add your own molecules\n",
    "test_smiles = [\n",
    "    \n",
    "    'C1=COC(=C1)C2=NN3C(=NC(=NC3=N2)NCCC4=CC=C(C=C4)O)N', #ZMA241385\n",
    "    'CN1C=NC2=C1C(=O)N(C(=O)N2C)C'                        #Cafeine\n",
    "]\n",
    "\n",
    "fps = []\n",
    "\n",
    "for smiles in test_smiles: \n",
    "    fp = smiles_to_fp(smiles,'morgan3')\n",
    "    fps.append(fp)\n",
    "\n",
    "predictions = trained_model.predict(fps)\n",
    "print(\"SMILES, PREDICTION\")\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print('{},{:.2f}'.format(test_smiles[i], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can paste a smiles string of a designed molecule in here yourself. It's probably a good idea to start close to molecules that are already in the training set (check ChEMBL for inspiration). Of course you can also go crazy and design what you like, but bear in mind that Machine Learning has that pesky applicability domain so the results you obtain might not be that accurate.\n",
    "\n",
    "You can generate SMILES strings for instance using the drawing function in molview (https://molview.org/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "* Which model performed best on our data set and why?\n",
    "    * All three models perform (very) well on our dataset. The best models are the random forest and support vector machine models which showed a mean AUC of about 90%. Our neural network showed slightly lower results. \n",
    "    * There might be several reasons that random forest and support vector machine models performed best. Our dataset might be easily separable in active/inactive with some simple tree-like decisions or with the radial basis function, respectively. Thus, there is not such a complex pattern in the fingerprints to do this classification.\n",
    "    * A cause for the slightly poorer performance of the ANN could be that there was simply too few data to train the model on.\n",
    "    * Additionally, it is always advisable to have another external validation set for model evaluation.  \n",
    "* Was MACCS the right choice?\n",
    "    * Obviously, MACCS was good to start training and validating models to see if a classification is possible. \n",
    "    * However, MACCS keys are rather short (166 bit) compared to others (2048 bit), as for example Morgan fingerprint. As shown in the last simulation, having longer fingerprint helps the learning process. All tested models performed slightly better using Morgan fingerprints (see mean AUC increase).\n",
    "\n",
    "    \n",
    "### Where can we go from here?\n",
    "\n",
    "* We successfully trained several models. \n",
    "* The next step could be to use these models to do a classification with an unknown screening dataset to predict novel potential EGFR inhibitors.\n",
    "* An example for a large screening data set is e.g. [MolPort](https://www.molport.com/shop/database-download) with over 7 million compounds.\n",
    "* Our models could be used to rank the MolPort compounds and then further study those with the highest predicted probability of being active.\n",
    "* For such an application, see also the [TDT Tutorial](https://github.com/sriniker/TDT-tutorial-2014) developed by S. Riniker and G. Landrum, where they trained a fusion model to screen [eMolecules](https://www.emolecules.com/) for new anti-malaria drugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "* How can you apply ML for virtual screening?\n",
    "* Which machine learning algorithms do you know?\n",
    "* What are necessary prerequisites to successfully apply ML?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
